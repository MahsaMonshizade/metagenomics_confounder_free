{
    "latent_dim": 64,
    "lr_r": 0.0001,
    "lr_g": 0.0001,
    "lr_c": 0.005,
    "activation_fn": "SiLU",
    "num_layers": 1
}